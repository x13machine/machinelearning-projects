{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "if(IPython.tab_as_tab_everywhere)IPython.tab_as_tab_everywhere()"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%javascript\n",
    "if(IPython.tab_as_tab_everywhere)IPython.tab_as_tab_everywhere()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os, sys, json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import hashlib\n",
    "\n",
    "# from tf.keras.models import Sequential  # This does not work!\n",
    "from tensorflow.python.keras.models import Sequential\n",
    "from tensorflow.python.keras.layers import InputLayer, Input\n",
    "from tensorflow.python.keras.layers import Reshape, MaxPooling2D,Dropout\n",
    "from tensorflow.python.keras.layers import Conv2D, Dense, Flatten\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.optimizers import Adam\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pd.set_option('display.max_rows', 50)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('data/application_train.csv', encoding='ISO-8859-1').sample(frac=1)\n",
    "train['INVERSE_TARGET'] = 1 - train['TARGET']\n",
    "train.loc[train['DAYS_EMPLOYED'] == 365243,'DAYS_EMPLOYED'] = 0\n",
    "train['DAYS_EMPLOYED'] = -train['DAYS_EMPLOYED']\n",
    "train['DAYS_BIRTH'] = -train['DAYS_BIRTH']\n",
    "train['DAYS_REGISTRATION'] = -train['DAYS_REGISTRATION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "df['CNT_CHILDREN'] = train['CNT_CHILDREN'].clip(0,4)\n",
    "df['DAYS_BIRTH'] = train['DAYS_BIRTH']\n",
    "df['DAYS_EMPLOYED'] = train['DAYS_EMPLOYED']\n",
    "df['DAYS_REGISTRATION'] = train['DAYS_REGISTRATION']\n",
    "\n",
    "#documents\n",
    "df['documents'] = 1\n",
    "for id_ in range(2,22):\n",
    "\tdf['documents'] += train['FLAG_DOCUMENT_' + str(id_)]\n",
    "\t\n",
    "#objects\n",
    "preprocess = {}\n",
    "for col in train:\n",
    "\tif train[col].dtype.kind in 'bif' and not col in ['TARGET','INVERSE_TARGET','SK_ID_CURR'] and not col in df.columns:\n",
    "\t\tnoNaN = train[col].count() == len(train)\n",
    "\t\tif noNaN:\n",
    "\t\t\tdf[col] = train[col]\n",
    "\t\telse:\n",
    "\t\t\tdf[col] = train[col].fillna(0)\n",
    "\t\t\tdf[col + '_nan'] = train[col].isna()\n",
    "\t\tpreprocess[col] ={\n",
    "\t\t\t'type':'num',\n",
    "\t\t\t'noNaN': int(noNaN)\n",
    "\t\t}\n",
    "\t\t\n",
    "\t\n",
    "\tif train[col].dtype != 'O': continue\n",
    "\t\n",
    "\ttrain[col] = train[col].fillna('none')\n",
    "\tdic = train.groupby([col])['TARGET'].mean().to_dict()\n",
    "\tpreprocess[col] = {\n",
    "\t\t'type':'dic',\n",
    "\t\t'dic':dic\n",
    "\t}\n",
    "\t\n",
    "\tdf[col] = train[col].map(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cols = pd.DataFrame(columns=['col','cor'])\n",
    "for col in df:\n",
    "\tcor = np.corrcoef(train['TARGET'],df[col])[0][1]\n",
    "\tuse_cols = use_cols.append({\n",
    "\t\t'col': col,\n",
    "\t\t'cor': cor,\n",
    "\t\t'abs': abs(cor)\n",
    "\t},ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "use = use_cols.sort_values(by=['abs'],ascending=False).head(150)['col'].tolist()\n",
    "df_use = df[use]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_norm = pd.DataFrame()\n",
    "\n",
    "lims = {}\n",
    "\n",
    "for col in df_use:\n",
    "\tcolumn = df_use[col]\n",
    "\td_min = float(column.min())\n",
    "\td_max = float(column.max())\n",
    "\tdif = d_max - d_min\n",
    "\t\n",
    "\tlims[col] = {\n",
    "\t\t'a': d_min,\n",
    "\t\t'b': dif,\n",
    "\t}\n",
    "\t\n",
    "\t\n",
    "\tdf_norm[col] = (df_use[col] - d_min) / dif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = len(df_use.columns)\n",
    "train_percent = 0.9\n",
    "train_num = int(len(train) * train_percent)\n",
    "test_num = len(train) - train_num\n",
    "\n",
    "train_x = df_norm.head(train_num).as_matrix()\n",
    "train_y = train[['TARGET','INVERSE_TARGET']].head(train_num).as_matrix()\n",
    "\n",
    "test_x = df_norm.tail(test_num).as_matrix()\n",
    "test_y = train[['TARGET','INVERSE_TARGET']].tail(test_num).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1a3a9138a352a568d1a66a15d31fdbe2'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hashlib.md5(str.encode(str(df_use.columns))).hexdigest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an input layer which is similar to a feed_dict in TensorFlow.\n",
    "# Note that the input-shape must be a tuple containing the image-size.\n",
    "inputs = Input(shape=(columns,))\n",
    "\n",
    "# Variable used for building the Neural Network.\n",
    "net = inputs\n",
    "\n",
    "# First fully-connected / dense layer with ReLU-activation.\n",
    "w = 300\n",
    "h = 4\n",
    "for _ in range(h):\n",
    "\tnet = Dense(w, activation='relu')(net)\n",
    "\n",
    "net = Dropout(0.5)(net)\n",
    "\n",
    "net = Dense(2, activation='softmax')(net)\n",
    "\n",
    "# Output of the Neural Network.\n",
    "outputs = net\n",
    "model = Model(inputs=inputs, outputs=outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='sgd', loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 221407 samples, validate on 55352 samples\n",
      "Epoch 1/10\n",
      "221407/221407 [==============================] - 12s 52us/step - loss: 0.2835 - val_loss: 0.2697\n",
      "Epoch 2/10\n",
      "221407/221407 [==============================] - 11s 50us/step - loss: 0.2640 - val_loss: 0.2587\n",
      "Epoch 3/10\n",
      "221407/221407 [==============================] - 11s 50us/step - loss: 0.2568 - val_loss: 0.2549\n",
      "Epoch 4/10\n",
      "221407/221407 [==============================] - 11s 50us/step - loss: 0.2546 - val_loss: 0.2541\n",
      "Epoch 5/10\n",
      "221407/221407 [==============================] - 11s 50us/step - loss: 0.2531 - val_loss: 0.2535\n",
      "Epoch 6/10\n",
      "221407/221407 [==============================] - 11s 50us/step - loss: 0.2527 - val_loss: 0.2542\n",
      "Epoch 7/10\n",
      "221407/221407 [==============================] - 11s 50us/step - loss: 0.2524 - val_loss: 0.2531\n",
      "Epoch 8/10\n",
      "221407/221407 [==============================] - 11s 50us/step - loss: 0.2519 - val_loss: 0.2531\n",
      "Epoch 9/10\n",
      "221407/221407 [==============================] - 11s 51us/step - loss: 0.2515 - val_loss: 0.2528\n",
      "Epoch 10/10\n",
      "221407/221407 [==============================] - 11s 50us/step - loss: 0.2513 - val_loss: 0.2524\n",
      "roc0 0.7443005592524423\n"
     ]
    }
   ],
   "source": [
    "for i in range(1):\n",
    "\tmodel.fit(x=train_x, y=train_y,validation_split=0.2,epochs=10, batch_size=128)\n",
    "\tprint('roc' + str(i),roc_auc_score(test_y[:,0],model.predict(test_x)[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('credit.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump({\n",
    "\t'preprocess': preprocess,\n",
    "\t'scale': lims,\n",
    "\t'use': use\n",
    "},open('credit.json', 'w'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7460604805884006"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(train_y[:,0],model.predict(train_x)[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
